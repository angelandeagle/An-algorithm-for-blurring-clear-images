import os
import cv2
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, LeakyReLU, BatchNormalization, Dropout
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow import keras
from sklearn.model_selection import train_test_split
import zipfile
import matplotlib.pyplot as plt

# 定义盲卷积层
class BlindDeconvolution(layers.Layer):
    def __init__(self, filters, kernel_size, padding='same', **kwargs):
        super(BlindDeconvolution, self).__init__(**kwargs)
        self.filters = filters
        self.kernel_size = kernel_size
        self.padding = padding

    def build(self, input_shape):
        self.kernel = self.add_weight(
            name='kernel',
            shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),
            initializer='glorot_uniform',
            trainable=True
        )
        self.bias = self.add_weight(
            name='bias',
            shape=(self.filters,),
            initializer='zeros',
            trainable=True
        )

    def call(self, inputs):
        deblurred = tf.nn.conv2d(inputs, self.kernel, strides=(1, 1, 1, 1), padding=self.padding)
        return tf.nn.bias_add(deblurred, self.bias)

    def get_config(self):
        config = super(BlindDeconvolution, self).get_config()
        config.update({
            'filters': self.filters,
            'kernel_size': self.kernel_size,
            'padding': self.padding
        })
        return config

# 定义去模糊 U-Net 模型
def deblur_unet(input_size=(128, 128, 3)):
    inputs = Input(input_size)
    
    # 编码器
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    blind_deconv1 = BlindDeconvolution(filters=64, kernel_size=3, padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(blind_deconv1)
    
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    blind_deconv2 = BlindDeconvolution(filters=128, kernel_size=3, padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(blind_deconv2)
    
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    blind_deconv3 = BlindDeconvolution(filters=256, kernel_size=3, padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(blind_deconv3)
    
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    blind_deconv4 = BlindDeconvolution(filters=512, kernel_size=3, padding='same')(conv4)
    drop4 = Dropout(0.5)(blind_deconv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    # 瓶颈
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    blind_deconv5 = BlindDeconvolution(filters=1024, kernel_size=3, padding='same')(conv5)
    drop5 = Dropout(0.5)(blind_deconv5)

    # 解码器
    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)
    blind_deconv6 = BlindDeconvolution(filters=512, kernel_size=3, padding='same')(conv6)

    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(blind_deconv6))
    merge7 = concatenate([blind_deconv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)
    blind_deconv7 = BlindDeconvolution(filters=256, kernel_size=3, padding='same')(conv7)

    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(blind_deconv7))
    merge8 = concatenate([blind_deconv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)
    blind_deconv8 = BlindDeconvolution(filters=128, kernel_size=3, padding='same')(conv8)

    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(blind_deconv8))
    merge9 = concatenate([blind_deconv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)
    blind_deconv9 = BlindDeconvolution(filters=64, kernel_size=3, padding='same')(conv9)

    conv10 = Conv2D(3, 1, activation='tanh')(blind_deconv9)

    model = Model(inputs=[inputs], outputs=[conv10])

    return model

# 定义综合损失函数
class CombinedLoss(keras.losses.Loss):
    def __init__(self, alpha=0.5, name="combined_loss", reduction=keras.losses.Reduction.SUM_OVER_BATCH_SIZE):
        super().__init__(name=name, reduction=reduction)
        self.alpha = alpha

    def call(self, y_true, y_pred):
        # L1损失
        l1_loss = tf.reduce_mean(tf.abs(y_true - y_pred))
        
        # SSIM损失
        ssim_loss = 1 - tf.image.ssim(y_true, y_pred, max_val=2.0)
        
        return self.alpha * l1_loss + (1 - self.alpha) * tf.reduce_mean(ssim_loss)

    def get_config(self):
        config = super(CombinedLoss, self).get_config()
        config.update({'alpha': self.alpha})
        return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)

# 数据预处理
def preprocess_image(image_path, target_size=(128, 128)):
    img = cv2.imread(image_path)
    if img is None:
        print(f"警告: 无法读取图像文件 {image_path}")
        return None, None
    
    # 确保图像是彩色图像（3通道）
    if len(img.shape) != 3 or img.shape[2] != 3:
        print(f"警告: 图像 {image_path} 不是彩色图像，已跳过")
        return None, None
    
    original_shape = img.shape  # 保存原始图片的形状
    img = cv2.resize(img, target_size)
    img = img.astype(np.float32) / 127.5 - 1.0  # Normalize to [-1, 1]
    
    # 确保图像形状正确
    if img.shape != (target_size[0], target_size[1], 3):
        print(f"警告: 图像 {image_path} 处理后形状不正确，已跳过")
        return None, None
    
    return img, original_shape

# 加载数据
def load_data(base_dir, max_scenes=25, target_size=(128, 128)):
    blur_images = []
    gt_images = []
    scenes = os.listdir(base_dir)
    print("总场景数:", len(scenes))
    
    scene_count = 0
    for scene in scenes:
        if scene_count >= max_scenes:
            break  # 只处理前 max_scenes 个场景
        
        scene_dir = os.path.join(base_dir, scene)
        if os.path.isdir(scene_dir):
            blur_dir = os.path.join(scene_dir, 'blur')
            gt_dir = os.path.join(scene_dir, 'gt')
            
            if os.path.exists(blur_dir) and os.path.exists(gt_dir):
                print(f"处理场景 {scene}")
                blur_files = os.listdir(blur_dir)
                print("  blur 文件数:", len(blur_files))
                
                for filename in blur_files:
                    if filename.endswith('.jpg') or filename.endswith('.png'):
                        # 提取文件名中的编号部分
                        base_name = os.path.splitext(filename)[0]
                        if base_name.startswith('blur_'):
                            # 构造对应的 gt 文件名
                            gt_filename = f"gt_{base_name[5:]}.png"
                            blur_path = os.path.join(blur_dir, filename)
                            gt_path = os.path.join(gt_dir, gt_filename)
                            
                            if os.path.exists(gt_path):
                                print(f"  加载文件 {filename}")
                                blur_img, _ = preprocess_image(blur_path, target_size)
                                gt_img, _ = preprocess_image(gt_path, target_size)
                                
                                if blur_img is not None and gt_img is not None:
                                    blur_images.append(blur_img)
                                    gt_images.append(gt_img)
                            else:
                                print(f"  警告: 未找到对应的 gt 文件 {gt_path}")
                scene_count += 1  # 增加场景计数
            else:
                print(f"  警告: 未找到 blur 或 gt 目录")
        else:
            print(f"  警告: 无效的场景目录 {scene_dir}")
    
    print("加载完成，总样本数:", len(blur_images))
    
    # 转换为 NumPy 数组之前验证形状
    if len(blur_images) == 0:
        print("警告: 没有有效的图像数据")
        return None, None
    
    # 检查所有图像的形状是否一致
    for img in blur_images + gt_images:
        if img.shape != (target_size[0], target_size[1], 3):
            print(f"警告: 发现形状不一致的图像，已跳过")
            return None, None
    
    return np.array(blur_images), np.array(gt_images)

# 创建去模糊 U-Net 模型
model = deblur_unet(input_size=(128, 128, 3))

# 编译模型
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    loss=CombinedLoss(alpha=0.5),
    metrics=['accuracy']
)

# 加载数据
dataset_dir = r"/kaggle/input/real21/rea"
X_train, y_train = load_data(dataset_dir, max_scenes=25)

if X_train is None or y_train is None:
    print("错误: 无法加载训练数据")
    # 在这里可以添加一些处理逻辑，例如退出程序或使用默认数据

# 手动划分训练集和验证集
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# 训练模型
history = model.fit(
    X_train, y_train,
    batch_size=4,
    epochs=50,
    validation_data=(X_val, y_val),
    callbacks=[
        keras.callbacks.ModelCheckpoint(
            filepath="best_deblur_model.keras",
            monitor='val_loss',
            verbose=1,
            save_best_only=True,
            mode='min'
        ),
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            verbose=1,
            mode='min'
        )
    ]
)

# 加载最佳模型
best_model = keras.models.load_model("best_deblur_model.keras", custom_objects={'BlindDeconvolution': BlindDeconvolution, 'CombinedLoss': CombinedLoss})

# 使用模型进行去模糊并保存结果
def deblur_and_save(model, input_dir, output_dir, target_size=(128, 128)):
    for filename in os.listdir(input_dir):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            input_path = os.path.join(input_dir, filename)
            img, original_shape = preprocess_image(input_path, target_size)
            if img is not None:
                img = np.expand_dims(img, axis=0)
                deblurred = model.predict(img)
                deblurred = (deblurred[0] + 1.0) * 127.5  # Denormalize to [0, 255]
                deblurred = deblurred.astype(np.uint8)
                # 调整回原始图片的形状
                deblurred = cv2.resize(deblurred, (original_shape[1], original_shape[0]))
                output_path = os.path.join(output_dir, filename)
                cv2.imwrite(output_path, deblurred)

input_dir = r"/kaggle/input/bisaishuju/给参赛者下载的数据/竞赛数据/Data"
output_dir = r"/kaggle/working/deblurred_results"
os.makedirs(output_dir, exist_ok=True)
deblur_and_save(best_model, input_dir, output_dir)

# 将结果打包成压缩文件
def file2zip(packagePath, zipPath):
    zip_file = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)
    for path, dirNames, fileNames in os.walk(packagePath):
        fpath = path.replace(packagePath, '')
        for name in fileNames:
            fullName = os.path.join(path, name)
            name = fpath + '/' + name
            zip_file.write(fullName, name)
    zip_file.close()

packagePath = '/kaggle/working/deblurred_results'
zipPath = '/kaggle/working/output.zip'
file2zip(packagePath, zipPath)
print("打包完成")
